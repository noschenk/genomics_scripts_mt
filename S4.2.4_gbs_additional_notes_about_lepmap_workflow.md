# additional notes about LepMap3 workflow
This file contains some additional information about how to construct a genetic map according to the [workflow reported by Michel](https://github.com/MichelMoser/GBS2map/blob/master/GBS2markerF7K.ipynb)

The genome used here is the one recieved from Bionano in 2018, which is already scaffolded with opticcal mapping data. It is called "P.exserta.opticalmap.v1.fasta" by now.

### 2. align QC reads to genome
Reads need to be mapped to the reference genome. When working with `bowtie2`, first an index of the reference genome needs to be made. An example script for use on the (UBELIX)[https://ubelix.unibe.ch/] cluster:

```
#!/bin/sh
#SBATCH --mail-user=noelle.schenk@students.unibe.ch
#SBATCH --mail-type=fail,end
#SBATCH --job-name="index"
# Mandatory resources (h_cpu=hh:mm:ss)
#SBATCH --mem-per-cpu=8G
#SBATCH --time=01:00:00
#SBATCH --tmp=8G
#SBATCH --workdir=.
#SBATCH --output=indexing.out
#SBATCH --error=indexing.err

################### execute code here ################

module load vital-it
module load UHTS/Aligner/bowtie2/2.3.4.1

bowtie2-build /gpfs/homefs/ips/ns12a545/om_genome/P.exserta.opticalmap.v1.fasta PeexOM
```
To add read groups and immediately convert .sam output from bowtie2 to .bam output could be :
```
#!/bin/sh
#SBATCH --mail-user=noelle.schenk@students.unibe.ch
#SBATCH --mail-type=fail,end
#SBATCH --job-name="mapex"
#SBATCH --mem-per-cpu=6G
#SBATCH --time=02:00:00
#SBATCH --tmp=8G
#SBATCH --cpus-per-task=4
#SBATCH --workdir=.
#SBATCH --output=ax.plate3.1.%j.out
#SBATCH --error=ax.plate3.1.%j.err

############################# execute code here################################

module load vital-it
module load UHTS/Aligner/bowtie2/2.3.1
module load UHTS/Analysis/samtools/1.8

READDIR='/gpfs/homefs/ips/ns12a545/gbs_to_ref/reads/hq_reads'

bowtie2 --very-sensitive --no-unal --rg-id ex --rg SM:blubb --rg LB:blubb --rg PI:blubby --rg PL:ILLUMINA -p 4 -x PeexOM -U ${READDIR}/plate3.1.q30l50.fq | samtools view -bS - > F7_plate3.1.b2.peexOM.bam
```
To sort the output \*.bam files:

**sort** .bam files.
```
#!/bin/sh
#SBATCH --mail-user=noelle.schenk@students.unibe.ch
#SBATCH --mail-type=fail,end
#SBATCH --job-name="sort"
#SBATCH --mem-per-cpu=6G
#SBATCH --time=02:00:00
#SBATCH --tmp=1G
#SBATCH --cpus-per-task=4
#SBATCH --workdir=.
#SBATCH --output=ax.plate3.1.%j.s.out
#SBATCH --error=ax.plate3.1.%j.s.err

############################# execute code here################################

module load vital-it
module load UHTS/Analysis/samtools/1.8

for file in *peexOM.bam
do
    samtools sort -@ 4 -m 6G -o *peexOM.s.bam $file
done
```


### 3. prepare fofn's for posterior calls and LM3
With the maped reads, SNPs which could serve as markers between *P.exserta* and *P.axillaris* can be searched and posterior probabilities for each genotype can be calculated.

As the amount of data is enormous, the job is splitted. [related post](https://github.com/samtools/samtools/issues/480) "What people usually do is to break the genome into regions and run them in parallel."

The splitting follows instructions [from Michel](https://github.com/MichelMoser/bioinformatic_scripts.git).

In order to run a python script on the cluster, the required python packages need to be installed. The UBELIX team provides information on [how to install](https://docs.id.unibe.ch/ubelix/software/python) `ANACONDA`, which contains many useful python packages, e.g. the following:

```
wget https://repo.continuum.io/archive/Anaconda3-4.2.0-Linux-x86_64.sh
bash Anaconda3-4.2.0-Linux-x86_64.sh
python --version
```
Then run the python script, e.g. to get 33 50Mbp long chunks:
```
#!/bin/sh
#SBATCH --mail-user=noelle.schenk@students.unibe.ch
#SBATCH --mail-type=fail,end
#SBATCH --job-name="chunk-to-bed"
#SBATCH --mem-per-cpu=2G
#SBATCH --time=02:00:00
##SBATCH --tmp=1G
#SBATCH --cpus-per-task=1
#SBATCH --workdir=.
#SBATCH --output=chunking.%j.out
#SBATCH --error=chunking.%j.err

############################# execute code here################################

module load vital-it
python3 fasta2bed.py --input /gpfs/homefs/ips/ns12a545/om_genome/P.exserta.opticalmap.v1.fasta --interval 50000000 --prefix PeexOM100M
```
### 3.1 Create posterior basecalls
Run slurm batch script obtained from Michel to obtain posterior probabilities in the folder `F7_K.PeexOM50M.bed*.bed.peexOM.post`.

The script requires the files `mapping.txt` and `bam_list.txt`.

#### mapping.txt
```
exserta exserta exserta axillaris axillaris axillaris RIL_196 RIL_197 RIL_198 RIL_199 RIL_200 RIL_201 RIL_202 ...
```
#### bam_list.txt
```
ex_plate3.1.b2.peexOM.s.bam ex_plate4.2.b2.peexOM.s.bam ex_plate1.94.b2.peexOM.s.bam ax_plate2.8.b2.peexOM.s.bam ax_plate1.93.b2.peexOM.s.bam ax_plate1.95.b2.peexOM.s.bam F7_plate2.89.b2.peexOM.s.bam F7_plate2.90.b2.peexOM.s.bam ...
```
same order as mapping.txt. The first entry in mapping.txt corresponds (is the name of) the first entry in bam_list.txt

```
#!/bin/bash                                 
#SBATCH --mail-user=noelle.schenk@students.unibe.ch
#SBATCH --mail-type=end,fail
#SBATCH --workdir=.                               
#SBATCH --time=50:00:00             ## Max runtime                                         
#SBATCH --mem=20g                 ## Max memory (m=MB, g= GB)                             
#SBATCH --output=lepPostprob_%j.out        ## Specified where standard output is redirected     
#SBATCH --error=lepPostprob_%j.err         ## Specified where error messages are redirected     
#SBATCH --job-name=postprob          ## Job name                                      
#SBATCH --cpus-per-task=1                   
#SBATCH --array=1-33

ARRAY=(*.bed)

echo ${ARRAY[*]}
echo ${SLURM_ARRAY_TASK_ID}

name=${ARRAY[${SLURM_ARRAY_TASK_ID}]}
echo $name

module load vital-it
module load UHTS/Analysis/samtools/1.4;

samtools mpileup -l ${name} -q 10 -Q 10 -s $(cat bam_list.txt) |awk -f scripts/pileupParser2.awk |awk -f scripts/pileup2posterior.awk |gzip > F7_K.${name}.peexOM.post.gz

samtools mpileup -l PeexOM50M.bed10.bed -q 10 -Q 10 -s $(cat bam_list.txt) |awk -f scripts/pileupParser2.awk |awk -f scripts/pileup2posterior.awk | gzip > F7_K.PeexOM50M.bed10.bed.peexOM.post.gz
```
Note that the first element in the list of chunks is not run in bash, therefore it must be run separately. In this case, the first element was `PeexOM50M.bed10.bed`, therefore `samtools mpileup` is run twice. To be sure all chunks were run, check if there is a `F7_K.PeexOM50M.bed*.bed.peexOM.post.gz` file for each chunk.

samtools mpileup parameteres : -Q minBaseQ = 10 -q minMapQ=10. minBaseQ: Minimum base quality for a base to be considered, minMapQ: Minimum mapping quality for an alignment to be used.

*pileupParser2* and *pileup2posterior* : creates posterior calls of SNPs.

#### \*.post.gz
The output file from `samtools mpileup ...`. tab-delimined. A diploid location on the genome has 10 possible genotypes:

"AA", "AC", "AG","AT", "CC", "CG", "CT", "GG", "GT" ,"TT"

For each sample, the probability of each genotypes is given as a number between 0 and 1.

| CHR   |  POS  |  exserta  | axillaris | RIL_196 | ... |
|------- | ------- | -------- | --------- | --------| -------- | -------- | --- |
| Super-Scaffold_40 |	251340 | 0	0	0	0	0	0	0	0	0	1 | 0	0	0	0	0	0	0	0	0	1 | 0	0	0	0	0	0	0	0	0	1 | ... |
| Super-Scaffold_40	| 251341 | 0	0	0	0	1	0	0	0	0	0 | 0	0	0	0	1	0	0	0	0	0 | 0	0	0	0	1	0	0	0	0	0 | ... |
| Super-Scaffold_40	| 251342 | 0	0	0	0	0	0	0	0	0	1 | 0	0	0	0	0	0	0	0	0	1 | 0	0	0	0	0	0	0	0	0	1 | ... |
| Super-Scaffold_40	| 251343 | 0	0	0	0	1	0	0	0	0	0 | 0	0	0	0	1	0	0	0	0	0 | 0	0	0	0	1	0	0	0	0	0 | ... |
| ... | ... | ... | ... | ... | ... |

### merge all \*post.gz files
removing headers and zip again.
```
touch ALLF7_K.PeexOM.post.gz
zcat F7_K.P*gz | grep -v 'CHR' > ALLF7_K.PeexOM.post.gz
zcat F7_K.PeexOM50M.bed10.bed.peexOM.post.gz | head -1 > header.txt
cat header.txt ALLF7_K.PeexOM.post.gz | gzip > F7_K.PeexOM.post.gz
rm ALLF7_K.PeexOM.post.gz header.txt
```
168660 markers were found.

### 3.2: transform pedigree.txt
#### pedigree.txt
For filtering of the posterior basecalls, `pedigree.txt` is needed. Although we work with a F7 population, it represents a F2. (more information [here](https://sourceforge.net/p/lep-map3/discussion/general/thread/c7ba83bc/?limit=25#74b7))

example `pedigree.txt` file:
```
F7	exserta	0	0	1	0
F7	axillaris	0	0	2	0
F7	P1	exserta	axillaris	1	0
F7	P2	exserta	axillaris	2	0
F7	RIL_196	P1	P2	0	0
F7	RIL_197	P1	P2	0	0
F7	RIL_198	P1	P2	0	0
F7	RIL_199	P1	P2	0	0
F7	RIL_200	P1	P2	0	0
F7	RIL_201	P1	P2	0	0
...
```
The first line describes the "mother" plant exserta, mother and father are unkwnown. The second line describes the "father" axillaris plant. `Lep-Map3` requires genders, even if this is not biologically accurate. The third and fourth lines represent F1 individuals named "P1" and "P2". They are crosses between mother exserta and father axillairs. "P1" is female, "P2" is male. The following lines are the RIL individuals, which area all crosses between F1 P1 and P2. Each RIL individual requires a separate line.

*note*: make sure there are no column headers any more when starting to work with the file.

The file needs to be converted to `pedigree.tped` format with following code:
```
#!/bin/sh
#SBATCH --mail-user=noelle.schenk@students.unibe.ch
#SBATCH --mail-type=fail,end

#SBATCH --job-name="lepmap"

# Mandatory resources (h_cpu=hh:mm:ss)
#SBATCH --mem-per-cpu=2G
#SBATCH --time=01:00:00

##SBATCH --tmp=1G

#SBATCH --cpus-per-task=1

#SBATCH --workdir=.

# change
#SBATCH --output=ped.%j.out
#SBATCH --error=ped.%j.err

############################# execute code here################################

scripts/transpose_tab pedigree.txt |awk '{print "CHR\tPOS\t"$0}' > pedigree.tped
```
The resulting file, `pedigree.tped` looks as following:
```
CHR	POS	F7	F7	F7	F7	F7	F7	F7	F7
CHR	POS	exserta	axillaris	P1	P2	RIL_196	RIL_197	RIL_198	RIL_199
CHR	POS	0	0	exserta	exserta	P1	P1	P1	P1
CHR	POS	0	0	axillaris	axillaris	P2	P2	P2	P2
CHR	POS	1	2	1	2	0	0	0	0
CHR	POS	0	0	0	0	0	0	0	0
```

### 3.3: create posterior calls with pedigree and posterior calls
Kind of filtering the posterior calls with the help of the pedigree information.

```
#!/bin/bash
#SBATCH --mail-user=noelle.schenk@students.unibe.ch
#SBATCH --mail-type=end,fail
#SBATCH --workdir=.                               
#SBATCH --time=2:00:00             ## Max runtime                                         
#SBATCH --mem=20g                 ## Max memory (m=MB, g= GB)                             
#SBATCH --output=lepFilterPost_%j.out        ## Specified where standard output is redirected     
#SBATCH --error=lepFilterPost_%j.err         ## Specified where error messages are redirected     
#SBATCH --job-name=FilterPost          ## Job name                                      
#SBATCH --cpus-per-task=1                   

module load vital-it/7
module load Development/java/latest

cat F7_K.PeexOM.post.gz |java -cp scripts/bin/ ParentCall2 data=pedigree.tped posteriorFile=- removeNonInformative=1  > F7_K.PeexOM.postcall
```
Resulted in 1917 informative markers.

## 4. Transfer and filter posterior calls to csv (to use as input in R/ASmap)
Take out first row starting with '#' and the pedigree starting with CHR. The columns 5 and 6 need to be taken out, because they contain information on 'P1' and 'P2'.

exserta	axillaris	P1	P2	RIL_196	RIL_197	RIL_198	RIL_1
 and add the header needed.
```
cat F7_K.PeexOM.postcall | grep -v 'CHR' | grep -v '#'  > noheader_F7_K.PeexOM.postcall
# take out columns for P1 and P2

cat noheader_F7_K.PeexOM.postcall | cut -f 1-4,7-300 > noPnoheader_F7_K.PeexOM.postcall

cat header.txt noPnoheader_F7_K.PeexOM.postcall > cF7_K.PeexOM.postcall
rm noheader_F7_K.PeexOM.postcall noPnoheader_F7_K.PeexOM.postcall
```
The resulting file is `cF7_K.PeexOM.postcall`.
